{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f68e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import librosa\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d59fa3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36909e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca83aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_SHAPE = (129, 501)\n",
    "RANDOM_SEED = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411a96d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MANDARIN',\n",
       "  'ARABIC',\n",
       "  'TAMIL',\n",
       "  'BENGALI',\n",
       "  'SINHALA',\n",
       "  'DIVEHI',\n",
       "  'URDU',\n",
       "  'BURMESE',\n",
       "  'HINDI',\n",
       "  'NEPALI'],\n",
       " 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(\"./STFT/\")\n",
    "classes,len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d45c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from focal_loss import BinaryFocalLoss\n",
    "import soundfile as sf\n",
    "#import tensorflow_addons as tfa\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm,tnrange,tqdm_notebook\n",
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import applications as app\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Dropout \n",
    "from tensorflow.keras.models import Sequential \n",
    "#from tensorflow.keras.applications import EfficientNetB4, ResNet50,ResNet101, VGG16, MobileNet, InceptionV3\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# Make sure your experiments are reproducible\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose,BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import Model, Sequential\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd\n",
    "from  ast import literal_eval\n",
    "from tensorflow.keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d74cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SumLayer(tf.keras.layers.Layer):\n",
    "\tdef __init__(self,**kwargs):\n",
    "\t\tsuper(SumLayer, self).__init__(**kwargs)\n",
    "\t#def get_config(self):\n",
    "\t#\tconfig = super().get_config().copy()\n",
    "\t#\treturn \n",
    "\t#def get_config(self):\n",
    "\t\t# Implement get_config to enable serialization. This is optional.\n",
    "\t#\tbase_config = super(SumLayer, self).get_config()\n",
    "\t#\tconfig = {\"initializer\": tf.keras.initializers.serialize(self.initializer)}\n",
    "\t#\treturn dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\trow_sum = tf.reduce_sum(inputs,2,keepdims=True)\n",
    "\t\treturn row_sum\n",
    "class SumLayer2(tf.keras.layers.Layer):\n",
    "\tdef __init__(self,**kwargs):\n",
    "\t\tsuper(SumLayer2, self).__init__(**kwargs)\n",
    "\t#def get_config(self):\n",
    "\t#\tconfig = super().get_config().copy()\n",
    "\t#\treturn \n",
    "\t#def get_config(self):\n",
    "\t\t# Implement get_config to enable serialization. This is optional.\n",
    "\t#\tbase_config = super(SumLayer, self).get_config()\n",
    "\t#\tconfig = {\"initializer\": tf.keras.initializers.serialize(self.initializer)}\n",
    "\t#\treturn dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\trow_sum = tf.reduce_sum(inputs,2,keepdims=True)\n",
    "\t\treturn row_sum\n",
    "class SumLayer3(tf.keras.layers.Layer):\n",
    "\tdef __init__(self,**kwargs):\n",
    "\t\tsuper(SumLayer3, self).__init__(**kwargs)\n",
    "\t#def get_config(self):\n",
    "\t#\tconfig = super().get_config().copy()\n",
    "\t#\treturn \n",
    "\t#def get_config(self):\n",
    "\t\t# Implement get_config to enable serialization. This is optional.\n",
    "\t#\tbase_config = super(SumLayer, self).get_config()\n",
    "\t#\tconfig = {\"initializer\": tf.keras.initializers.serialize(self.initializer)}\n",
    "\t#\treturn dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\trow_sum = tf.reduce_sum(inputs,2,keepdims=True)\n",
    "\t\treturn row_sum\n",
    "\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "\tdef __init__(self,**kwargs):\n",
    "\t\tsuper(ScaleLayer, self).__init__(**kwargs)\n",
    "\t#def get_config(self):\n",
    "\t#\tconfig = super().get_config().copy()\n",
    "\t#\treturn config\n",
    "\t#def get_config(self):\n",
    "        # Implement get_config to enable serialization. This is optional.\n",
    "\t#\tbase_config = super(ScaleLayer, self).get_config()\n",
    "\t\t#config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "\t#\treturn dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\trow_sum = tf.reduce_sum(inputs,2,keepdims=True) + 10**-8 #added this to stop nans\n",
    "\t\tinput_norm = tf.divide(inputs,row_sum)\n",
    "\t\treturn input_norm\n",
    "\n",
    "class ScaleLayer2(tf.keras.layers.Layer):\n",
    "\tdef __init__(self,**kwargs):\n",
    "\t\tsuper(ScaleLayer2, self).__init__(**kwargs)\n",
    "\t#def get_config(self):\n",
    "\t#\tconfig = super().get_config().copy()\n",
    "\t#\treturn config\n",
    "\t#def get_config(self):\n",
    "        # Implement get_config to enable serialization. This is optional.\n",
    "\t#\tbase_config = super(ScaleLayer, self).get_config()\n",
    "\t\t#config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "\t#\treturn dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\trow_sum = tf.reduce_sum(inputs,2,keepdims=True) + 10**-8 #added this to stop nans\n",
    "\t\tinput_norm = tf.divide(inputs,row_sum)\n",
    "\t\treturn input_norm\n",
    "\n",
    "class ScaleLayer3(tf.keras.layers.Layer):\n",
    "\tdef __init__(self,**kwargs):\n",
    "\t\tsuper(ScaleLayer3, self).__init__(**kwargs)\n",
    "\t#def get_config(self):\n",
    "\t#\tconfig = super().get_config().copy()\n",
    "\t#\treturn config\n",
    "\t#def get_config(self):\n",
    "        # Implement get_config to enable serialization. This is optional.\n",
    "\t#\tbase_config = super(ScaleLayer, self).get_config()\n",
    "\t\t#config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "\t#\treturn dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\trow_sum = tf.reduce_sum(inputs,2,keepdims=True) + 10**-8 #added this to stop nans\n",
    "\t\tinput_norm = tf.divide(inputs,row_sum)\n",
    "\t\treturn input_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ee4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tf(num_classes,l2_str=10**-4):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3),input_shape=(SPEC_SHAPE[0],SPEC_SHAPE[1], 1),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(16, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "# Second conv block\n",
    "    tf.keras.layers.Conv2D(32, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "\n",
    "# Third conv block        \n",
    "    tf.keras.layers.Conv2D(64, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "        \n",
    "        \n",
    "  \n",
    "# Fourth conv block\n",
    "    tf.keras.layers.Conv2D(128, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "        \n",
    "# Fifth conv block\n",
    "    tf.keras.layers.Conv2D(512, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "        \n",
    "        \n",
    "# Sixth conv block\n",
    "    tf.keras.layers.Conv2D(512, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),  \n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3, 3),strides=1, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "        \n",
    " # Seventh conv block\n",
    "    tf.keras.layers.Conv2D(1024, (2, 2),strides=1, padding='valid'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),          \n",
    " # Eighth conv block\n",
    "    tf.keras.layers.Conv2D(2048, (1, 1)),#activation='sigmoid'),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.ReLU(),\n",
    " #Final BLock\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(2048, activation='relu',kernel_regularizer=l2(l2_str), bias_regularizer=l2(l2_str)),   \n",
    "    #tf.keras.layers.Dropout(0.5),  \n",
    "    tf.keras.layers.Dense(1024, activation='relu',kernel_regularizer=l2(l2_str), bias_regularizer=l2(l2_str)),\n",
    "    #tf.keras.layers.Dropout(0.5),   \n",
    "    tf.keras.layers.Dense(512, activation='relu',kernel_regularizer=l2(l2_str), bias_regularizer=l2(l2_str)),   \n",
    "    #tf.keras.layers.Dropout(0.5),])\n",
    "    tf.keras.layers.Dense(num_classes, activation='sigmoid')])\n",
    "    ## a fully covolutional NN !\n",
    "    print('MODEL HAS {} PARAMETERS.'.format(model.count_params()))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954405fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL HAS 19007226 PARAMETERS.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 129, 501, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 129, 501, 16)      64        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 129, 501, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 129, 501, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 129, 501, 16)      64        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 129, 501, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 250, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 250, 32)       4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 250, 32)       128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 64, 250, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 250, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 250, 32)       128       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 64, 250, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 125, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 125, 64)       18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 125, 64)       256       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 32, 125, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 125, 64)       36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 125, 64)       256       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 32, 125, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 62, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 16, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 62, 128)       147584    \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 16, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 31, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 31, 512)        590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 31, 512)        2048      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 8, 31, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 31, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 31, 512)        2048      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 8, 31, 512)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 15, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 15, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 15, 512)        2048      \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 4, 15, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 15, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 15, 512)        2048      \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 4, 15, 512)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 1, 6, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 6, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 1, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 6, 2048)        2099200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 6, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 1, 6, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 19,007,226\n",
      "Trainable params: 18,996,026\n",
      "Non-trainable params: 11,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=model_tf(len(classes))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf61da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(x, n_holes=1, length=40):   #time-freq masking\n",
    "\t\"Cut out `n_holes` number of rectangular bands of size `length` in image at random locations.\"\n",
    "\th,w = x.shape\n",
    "\t#print(h,w)\n",
    "\tfor n in range(n_holes):\n",
    "\t\th_y = np.random.randint(0, h)\n",
    "\t\th_x = np.random.randint(0, w)\n",
    "        \t#print(h_x,h_y)\n",
    "\t\ty1 = int(np.clip(h_y - length / 2,0, h))\n",
    "\t\ty2 = int(np.clip(h_y + length / 2,0, h))\n",
    "\t\tx1 = int(np.clip(h_x - length / 2,0, w))\n",
    "\t\tx2 = int(np.clip(h_x + length / 2,0, w))\n",
    "\t\tx[:, y1:y2] = 0\n",
    "\t\tx[x1:x2,:] = 0\n",
    "\treturn x\n",
    "\t\n",
    "def mixup_specs(x1,y1,x2,y2):\n",
    "\talpha = np.random.beta(1,1,1)\n",
    "    \t#print('alpha',alpha)\n",
    "\tx_new = alpha*x1 + (1-alpha)*x2\n",
    "\ty_new = alpha*y1 + (1-alpha)*y2\n",
    "\t##y_new = y1 + y2  # experimenting with not scaling down the labels\n",
    "\treturn x_new,y_new\n",
    "\n",
    "def mixup_func(mixup,X_train,y_train):\n",
    "\tlen_mixup = len(mixup)\n",
    "\tif(len_mixup >1):\n",
    "\t\tfor w in range(len_mixup-1):\n",
    "\t\t\tif(len_mixup ==1):\n",
    "\t\t\t\tbreak\n",
    "\t\t\tmixup_files = mixup[w],mixup[w+1]\n",
    "\t\t\tidx1 = mixup_files[0][1]\n",
    "\t\t\tidx2 = mixup_files[1][1]\n",
    "\t\t\tdata_idx1 = X_train[idx1]\n",
    "\t\t\tdata_idx2 = X_train[idx2]\n",
    "\t\t\tlabel_idx1 = y_train[idx1]\n",
    "\t\t\tlabel_idx2 = y_train[idx2]\n",
    "\t\t\tnew_data,new_label = mixup_specs(data_idx1,label_idx1,data_idx2,label_idx2)\n",
    "\t\t\tnew_data -= new_data.min()\n",
    "\t\t\tnew_data /= new_data.max()\n",
    "\t\t\tX_train[idx1] = new_data\n",
    "\t\t\ty_train[idx1] = new_label\n",
    "\treturn X_train,y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47e4c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(samples,labels,le,batch_size=32,n_classes=397):\n",
    "\tnum_samples = len(samples)\n",
    "\tidxs = np.arange(num_samples)\n",
    "\twhile True: # Loop forever so the generator never terminate\n",
    "\t\tshuffle(idxs)\n",
    "\t\tfor offset in range(0, num_samples, batch_size):\n",
    "                                # Get the samples you'll use in this batch\n",
    "\t\t\tidx = idxs[offset:offset+batch_size]\n",
    "\t\t\tbatch_samples = [samples[x] for x in idx]\n",
    "\t\t\tbatch_labels = np.array([labels[x] for x in idx])\n",
    "                        # Initialise X_train and y_train arrays for this batch\n",
    "\t\t\tX_train =  [] \n",
    "\t\t\ty_train = [] \n",
    "\t\t\tmixup=[]\n",
    "            \t\t# For each example\n",
    "\t\t\tfor p,ID in enumerate (batch_samples):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\taudio_path,secondary_labels = ID\n",
    "\t\t\t\t\tspec = Image.open(audio_path) # here ID is path\n",
    "                        \t\t# Convert to numpy array\n",
    "\t\t\t\t\tspec = np.array(spec, dtype='float32')\n",
    "\t\t\t\t\tif(spec.shape != (128,625)):  # checking the size of the spectrogram\n",
    "\t\t\t\t\t\tcontinue\n",
    "                        \t\t# Normalize between 0.0 and 1.0\n",
    "                        \t\t# and exclude samples with nan\n",
    "\t\t\t\t\tspec -= spec.min()\n",
    "\t\t\t\t\tspec /= spec.max()\n",
    "\t\t\t\t\tif not spec.max() == 1.0 or not spec.min() == 0.0:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t#power_range =np.arange(1.0,3.0,0.5)\n",
    "\t\t\t\t\t#spec_pow = np.random.choice(power_range)\n",
    "\t\t\t\t\t##spec_pow_noisy =  have twp spec powers for noisy and for rest, appply on all at random \n",
    "\t\t\t\t\t#if((\"time\" in ID) or (\"freq\" in ID)):\n",
    "\t\t\t\t\t\t#toss = np.random.binomial(1,0.5)\n",
    "\t\t\t\t\t\t#if(toss):\n",
    "\t\t\t\t\t\t\t#spec = spec**spec_pow   # no further increasin the noise\n",
    "\t\t\t\t\t##if(not(\"pink\" in ID) or (\"gauss\" in ID) or (\"time\" in ID) or (\"freq\" in ID)):  # only supposedly pure samples\n",
    "\t\t\t\t\t\t##toss_cutout = np.random.binomial(1,0.5)\n",
    "\t\t\t\t\t\t##if(len(secondary_labels) == 0):  ##spec masking for sec labels less 1 ie for single_labels\n",
    "\t\t\t\t\t\t\t##if(toss_cutout):\n",
    "\t\t\t\t\t\t\t\t##spec = cutout(spec,2)\n",
    "\t\t\t\t\tspec = np.expand_dims(spec, -1)\n",
    "\t\t\t\t\tspec = np.expand_dims(spec, 0)\n",
    "\t\t\t\t\t##spec = np.repeat(spec, 3, axis=2)\n",
    "                    \t\t\t#Add new dimension for batch size\n",
    "\t\t\t\t\tif(len(X_train)==0):\n",
    "\t\t\t\t\t\tX_train = spec\n",
    "\t\t\t\t\t\tindex = idx[p]\n",
    "\t\t\t\t\t\ty_tr = tf.keras.utils.to_categorical(labels[index], num_classes=n_classes)*1.0\n",
    "\t\t\t\t\t\ty_tr = np.expand_dims(y_tr,0)\n",
    "\t\t\t\t\t\tif(len(secondary_labels)> 0):\n",
    "\t\t\t\t\t\t\tsec_label_indices = le.transform(secondary_labels)\n",
    "\t\t\t\t\t\t\ty_tr[:,sec_label_indices] = 1.0 ## 1.0 worked well\n",
    "\t\t\t\t\t\ty_train = y_tr\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tX_train = np.append(X_train,spec,axis=0)\n",
    "\t\t\t\t\t\tindex = idx[p]\n",
    "\t\t\t\t\t\ty_tr = tf.keras.utils.to_categorical(labels[index], num_classes=n_classes)*1.0\n",
    "\t\t\t\t\t\ty_tr = np.expand_dims(y_tr,0)\n",
    "\t\t\t\t\t\tif(len(secondary_labels) > 0):\n",
    "\t\t\t\t\t\t\tsec_label_indices = le.transform(secondary_labels)\n",
    "\t\t\t\t\t\t\ty_tr[:,sec_label_indices] = 1.0  ##increased from 0.25 to 1.0 worked well ,lets try 0.50\n",
    "\t\t\t\t\t\ty_train = np.append(y_train,y_tr,axis=0)\n",
    "\t\t\t\t\t##if(not(('gauss' in ID) or ('pink' in ID))):\n",
    "\t\t\t\t\t\t##if(len(secondary_labels) ==0):\n",
    "\t\t\t\t\t\t\t##toss2 = np.random.binomial(1,0.40)  # since we are working wiht secondary labels , reducing chance of mixup\n",
    "\t\t\t\t\t\t\t##if(toss2):\n",
    "\t\t\t\t\t\t\t\t##mixup.append((ID,len(X_train)-1)) \n",
    "\t\t\t\texcept Exception as e:\n",
    "                    \t\t\t#print(e)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t##mixup_func(mixup,X_train,y_train) ##function to perform mixups based on beta distribution\n",
    "\t\t\tyield X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "883bc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##datagn and train the langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3cbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c84a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c39d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32de5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.sample(classes,5) # use random sample for getting 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "976115a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BURMESE', 'NEPALI', 'SINHALA', 'SINHALA', 'NEPALI', 'NEPALI',\n",
       "       'NEPALI', 'ARABIC', 'BENGALI', 'HINDI'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(classes,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9974f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6bb078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aba0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b6c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 6])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['BURMESE', 'HINDI', 'ARABIC', 'NEPALI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced769a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(le.transform(['BURMESE', 'HINDI', 'ARABIC', 'NEPALI']), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72dc01fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./STFT/MANDARIN/common_voice_zh-TW_26193532.png',\n",
       "  './STFT/MANDARIN/common_voice_zh-TW_19234302.png',\n",
       "  './STFT/MANDARIN/common_voice_zh-TW_20129587.png',\n",
       "  './STFT/MANDARIN/common_voice_zh-CN_26578371.png',\n",
       "  './STFT/MANDARIN/common_voice_zh-TW_22787706.png'],\n",
       " 100000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_train = []  # randomly sample files @10000 per class , oversampled if less\n",
    "for c in classes:\n",
    "    temp_files = glob.glob(\"./STFT/\"+c+\"/*.png\")\n",
    "    #if(len(temp_files) <10000):\n",
    "    temp = np.random.choice(temp_files,10000)\n",
    "    files_to_train.extend(temp)\n",
    "    #else:\n",
    "files_to_train[:5],len(files_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b122d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./STFT/NEPALI/02bba24bc4.png',\n",
       " './STFT/NEPALI/426636fed4_0.png',\n",
       " './STFT/NEPALI/13b634c809_1.png',\n",
       " './STFT/NEPALI/10d9dd5f3e_0.png',\n",
       " './STFT/NEPALI/19cd3e65db.png']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ace717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./STFT/TAMIL/common_voice_ta_20577366_0.png',\n",
       " './STFT/URDU/common_voice_ur_26630147_0.png',\n",
       " './STFT/URDU/common_voice_ur_26657604.png',\n",
       " './STFT/BURMESE/bur_5903_1850103318_0.png',\n",
       " './STFT/DIVEHI/common_voice_dv_25485223.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_train = random.sample(files_to_train,len(files_to_train))\n",
    "files_to_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764e8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc6c9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'./STFT/MANDARIN/common_voice_zh-TW_22787571.png'.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c261e75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TAMIL', 'URDU', 'URDU', 'BURMESE', 'DIVEHI'], 100000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [x.split(\"/\")[2] for x in files_to_train]\n",
    "labels[:5],len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64cd5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8e7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6601a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 8, 6, 4, 3]), 100000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = le.transform(labels)\n",
    "labels[-5:],len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81233c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c80a0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##10,000 spects from each class oversample if less,i.e 11 Hrs per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bf8074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30000*4/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ad8085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(samples,labels,le,batch_size=32,n_classes=10):\n",
    "    num_samples = len(samples)\n",
    "    idxs = np.arange(num_samples)\n",
    "    while True: # Loop forever so the generator never terminate\n",
    "        shuffle(idxs)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "                                # Get the samples you'll use in this batch\n",
    "            idx = idxs[offset:offset+batch_size]\n",
    "            batch_samples = [samples[x] for x in idx]\n",
    "            batch_labels = np.array([labels[x] for x in idx])\n",
    "          #  print(\"SHAPES at TOP: \",len(batch_samples),batch_labels.shape)\n",
    "                        # Initialise X_train and y_train arrays for this batch\n",
    "            X_train =  [] \n",
    "            y_train = [] \n",
    "           # mixup=[]\n",
    "                    # For each example\n",
    "            for path,label in zip(batch_samples,batch_labels):\n",
    "                try:\n",
    "                    audio_path = path\n",
    "                    spec = Image.open(audio_path) # here ID is path\n",
    "                                # Convert to numpy array\n",
    "                    spec = np.array(spec, dtype='float32')\n",
    "                    if(spec.shape != SPEC_SHAPE):  # checking the size of the spectrogram\n",
    "                        continue\n",
    "                        \t\t# Normalize between 0.0 and 1.0\n",
    "                        \t\t# and exclude samples with nan\n",
    "                    spec -= spec.min()\n",
    "                    spec /= spec.max()\n",
    "                    if not spec.max() == 1.0 or not spec.min() == 0.0:\n",
    "                        continue\n",
    "                    #power_range =np.arange(1.0,3.0,0.5)\n",
    "                    #spec_pow = np.random.choice(power_range)\n",
    "                    ##spec_pow_noisy =  have twp spec powers for noisy and for rest, appply on all at random \n",
    "                    #if((\"time\" in ID) or (\"freq\" in ID)):\n",
    "                        #toss = np.random.binomial(1,0.5)\n",
    "                        #if(toss):\n",
    "                            #spec = spec**spec_pow   # no further increasin the noise\n",
    "                    ##if(not(\"pink\" in ID) or (\"gauss\" in ID) or (\"time\" in ID) or (\"freq\" in ID)):  # only supposedly pure samples\n",
    "                        ##toss_cutout = np.random.binomial(1,0.5)\n",
    "                        ##if(len(secondary_labels) == 0):  ##spec masking for sec labels less 1 ie for single_labels\n",
    "                            ##if(toss_cutout):\n",
    "                                ##spec = cutout(spec,2)\n",
    "                    spec = np.expand_dims(spec, -1)\n",
    "                    spec = np.expand_dims(spec, 0)\n",
    "                    ##spec = np.repeat(spec, 3, axis=2)\n",
    "                                #Add new dimension for batch size\n",
    "                    if(len(X_train)==0):\n",
    "                        X_train = spec\n",
    "                        #index = idx[p]\n",
    "                        y_tr = tf.keras.utils.to_categorical(label, num_classes=n_classes)\n",
    "                        y_tr = np.expand_dims(y_tr,0)\n",
    "                        y_train = y_tr\n",
    "                    else:\n",
    "                        X_train = np.append(X_train,spec,axis=0)\n",
    "                        #index = idx[p]\n",
    "                        y_tr = tf.keras.utils.to_categorical(label, num_classes=n_classes)\n",
    "                        y_tr = np.expand_dims(y_tr,0)\n",
    "                        y_train = np.append(y_train,y_tr,axis=0)\n",
    "                    ##if(not(('gauss' in ID) or ('pink' in ID))):\n",
    "                        ##if(len(secondary_labels) ==0):\n",
    "                            ##toss2 = np.random.binomial(1,0.40)  # since we are working wiht secondary labels , reducing chance of mixup\n",
    "                            ##if(toss2):\n",
    "                                ##mixup.append((ID,len(X_train)-1)) \n",
    "                except Exception as e:\n",
    "                    print(\"XCEptionn: \",e)\n",
    "                    continue\n",
    "            ##mixup_func(mixup,X_train,y_train) ##function to perform mixups based on beta distribution\n",
    "           # print(X_train.shape,y_train.shape)\n",
    "            yield X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad7a9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##tr_batch = train_generator(files_to_train,labels,le,batch_size=32,n_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ae9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train,files_val,labels_train,labels_val = train_test_split(files_to_train,labels,test_size=0.05,stratify=labels,random_state=1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "704fa2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 5000, 95000, 5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_train),len(files_val),len(labels_train),len(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7d59050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./STFT/DIVEHI/common_voice_dv_23718251_0.png',\n",
       "  './STFT/ARABIC/common_voice_ar_24154512.png',\n",
       "  './STFT/ARABIC/common_voice_ar_19227175.png',\n",
       "  './STFT/DIVEHI/common_voice_dv_26617513_0.png',\n",
       "  './STFT/TAMIL/common_voice_ta_20513729.png'],\n",
       " array([3, 0, 0, 3, 8]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train[:5],labels_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3492ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes  = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1d8dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ed8ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for batch in tr_batch:\n",
    "    #print(batch[0].shape,batch[1].shape)\n",
    "    #print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e5b2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              loss =tf.keras.losses.BinaryCrossentropy(label_smoothing=0.025),\n",
    "               #loss=BinaryFocalLoss(gamma=2,label_smoothing=0.025),\n",
    "               #tfa.losses.SigmoidFocalCrossEntropy(alpha= 0.25,gamma= 2.0), \n",
    "               #tf.keras.losses.BinaryCrossentropy(label_smoothing=0.025)\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),\n",
    "              tf.keras.metrics.AUC(curve='PR',)])#multi_label=False),])\n",
    "              ##tfa.metrics.F1Score(average='micro',num_classes=num_classes,threshold=0.50)])\n",
    "            #tfa.metrics.F1Score(num_classes=len(dicts),average='micro',threshold= 0.25,name= 'f1_score_thresh_0.25'),\n",
    "            #tfa.metrics.F1Score(num_classes=len(dicts),average='micro',threshold=0.50,name = 'f1_score_thresh_0.50') ]) ##remove accuracy from the metrics\n",
    "            #try to use multiple instances with different thresholds!\n",
    "            #Add callbacks to reduce the learning rate if needed, early stopping, and checkpoint saving\n",
    "model_path = os.path.join(  \"./logs/exp1/\",'simple_64_10000_per_class.h5')\n",
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                  patience=2, \n",
    "                                                  verbose=1, \n",
    "                                                  factor=0.5),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              verbose=1,\n",
    "                                              patience=5),\n",
    "            tf.keras.callbacks.ModelCheckpoint(model_path, \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=0,\n",
    "                                                save_best_only=True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir= \"./logs/exp2/\",\n",
    "                                        histogram_freq=1,\n",
    "                                        write_graph = True,\n",
    "                                        write_images=False,\n",
    "                                        profile_batch=0)]  # for tensorflow >= 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b855ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_generator(files_train,labels_train,le,batch_size=num_batch_size,n_classes=len(classes))\n",
    "val_gen = train_generator(files_val,labels_val,le,batch_size=num_batch_size,n_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0fd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1484 steps, validate for 78 steps\n",
      "Epoch 1/50\n",
      "1484/1484 [==============================] - 1362s 918ms/step - loss: 0.2373 - accuracy: 0.9450 - precision: 0.8183 - recall: 0.5777 - auc: 0.7813 - val_loss: 0.4159 - val_accuracy: 0.8757 - val_precision: 0.3646 - val_recall: 0.3278 - val_auc: 0.3391\n",
      "Epoch 2/50\n",
      "1484/1484 [==============================] - 611s 412ms/step - loss: 0.1271 - accuracy: 0.9783 - precision: 0.9165 - recall: 0.8617 - auc: 0.9528 - val_loss: 0.2608 - val_accuracy: 0.9286 - val_precision: 0.6719 - val_recall: 0.5591 - val_auc: 0.6494\n",
      "Epoch 3/50\n",
      "1484/1484 [==============================] - 637s 429ms/step - loss: 0.1064 - accuracy: 0.9866 - precision: 0.9472 - recall: 0.9172 - auc: 0.9796 - val_loss: 0.3588 - val_accuracy: 0.8874 - val_precision: 0.4309 - val_recall: 0.3941 - val_auc: 0.4506\n",
      "Epoch 4/50\n",
      "1484/1484 [==============================] - 632s 426ms/step - loss: 0.0973 - accuracy: 0.9907 - precision: 0.9626 - recall: 0.9434 - auc: 0.9880 - val_loss: 0.2556 - val_accuracy: 0.9292 - val_precision: 0.6685 - val_recall: 0.5795 - val_auc: 0.6999\n",
      "Epoch 5/50\n",
      "1484/1484 [==============================] - 618s 416ms/step - loss: 0.0917 - accuracy: 0.9930 - precision: 0.9717 - recall: 0.9578 - auc: 0.9922 - val_loss: 0.1501 - val_accuracy: 0.9688 - val_precision: 0.8586 - val_recall: 0.8231 - val_auc: 0.9083\n",
      "Epoch 6/50\n",
      "1484/1484 [==============================] - 615s 414ms/step - loss: 0.0873 - accuracy: 0.9946 - precision: 0.9780 - recall: 0.9676 - auc: 0.9946 - val_loss: 0.1422 - val_accuracy: 0.9723 - val_precision: 0.8716 - val_recall: 0.8474 - val_auc: 0.9280\n",
      "Epoch 7/50\n",
      "1484/1484 [==============================] - 619s 417ms/step - loss: 0.0848 - accuracy: 0.9955 - precision: 0.9817 - recall: 0.9727 - auc: 0.9962 - val_loss: 0.3844 - val_accuracy: 0.8947 - val_precision: 0.4702 - val_recall: 0.4209 - val_auc: 0.4382\n",
      "Epoch 8/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9964 - precision: 0.9852 - recall: 0.9789 - auc: 0.9972\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1484/1484 [==============================] - 620s 417ms/step - loss: 0.0823 - accuracy: 0.9964 - precision: 0.9851 - recall: 0.9789 - auc: 0.9972 - val_loss: 0.2910 - val_accuracy: 0.9202 - val_precision: 0.6093 - val_recall: 0.5621 - val_auc: 0.6371\n",
      "Epoch 9/50\n",
      "1484/1484 [==============================] - 619s 417ms/step - loss: 0.0744 - accuracy: 0.9985 - precision: 0.9941 - recall: 0.9908 - auc: 0.9992 - val_loss: 0.2198 - val_accuracy: 0.9509 - val_precision: 0.7599 - val_recall: 0.7435 - val_auc: 0.7772\n",
      "Epoch 10/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9992 - precision: 0.9970 - recall: 0.9946 - auc: 0.9995\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1484/1484 [==============================] - 617s 416ms/step - loss: 0.0724 - accuracy: 0.9992 - precision: 0.9970 - recall: 0.9946 - auc: 0.9995 - val_loss: 0.1492 - val_accuracy: 0.9727 - val_precision: 0.8746 - val_recall: 0.8492 - val_auc: 0.9004\n",
      "Epoch 11/50\n",
      "1484/1484 [==============================] - 617s 416ms/step - loss: 0.0708 - accuracy: 0.9996 - precision: 0.9984 - recall: 0.9972 - auc: 0.9998 - val_loss: 0.0783 - val_accuracy: 0.9964 - val_precision: 0.9849 - val_recall: 0.9789 - val_auc: 0.9977\n",
      "Epoch 12/50\n",
      "1484/1484 [==============================] - 615s 415ms/step - loss: 0.0700 - accuracy: 0.9998 - precision: 0.9993 - recall: 0.9983 - auc: 0.9999 - val_loss: 0.0828 - val_accuracy: 0.9950 - val_precision: 0.9809 - val_recall: 0.9688 - val_auc: 0.9936\n",
      "Epoch 13/50\n",
      "1484/1484 [==============================] - 617s 415ms/step - loss: 0.0696 - accuracy: 0.9998 - precision: 0.9996 - recall: 0.9988 - auc: 0.9999 - val_loss: 0.0779 - val_accuracy: 0.9964 - val_precision: 0.9861 - val_recall: 0.9781 - val_auc: 0.9978\n",
      "Epoch 14/50\n",
      "1484/1484 [==============================] - 619s 417ms/step - loss: 0.0694 - accuracy: 0.9999 - precision: 0.9996 - recall: 0.9991 - auc: 0.9999 - val_loss: 0.3092 - val_accuracy: 0.9195 - val_precision: 0.6024 - val_recall: 0.5747 - val_auc: 0.5658\n",
      "Epoch 15/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9998 - precision: 0.9993 - recall: 0.9987 - auc: 0.9999\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1484/1484 [==============================] - 619s 417ms/step - loss: 0.0695 - accuracy: 0.9998 - precision: 0.9993 - recall: 0.9987 - auc: 0.9999 - val_loss: 0.1592 - val_accuracy: 0.9689 - val_precision: 0.8500 - val_recall: 0.8369 - val_auc: 0.8687\n",
      "Epoch 16/50\n",
      "1484/1484 [==============================] - 619s 417ms/step - loss: 0.0688 - accuracy: 0.9999 - precision: 0.9998 - recall: 0.9995 - auc: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9971 - val_precision: 0.9890 - val_recall: 0.9816 - val_auc: 0.9975\n",
      "Epoch 17/50\n",
      "1484/1484 [==============================] - 620s 417ms/step - loss: 0.0686 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9996 - auc: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9895 - val_precision: 0.9523 - val_recall: 0.9427 - val_auc: 0.9818\n",
      "Epoch 18/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9996 - auc: 1.0000\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1484/1484 [==============================] - 621s 418ms/step - loss: 0.0685 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9996 - auc: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9815 - val_precision: 0.9146 - val_recall: 0.8989 - val_auc: 0.9525\n",
      "Epoch 19/50\n",
      "1484/1484 [==============================] - 620s 418ms/step - loss: 0.0683 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9972 - val_precision: 0.9894 - val_recall: 0.9824 - val_auc: 0.9981\n",
      "Epoch 20/50\n",
      "1484/1484 [==============================] - 622s 419ms/step - loss: 0.0683 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9998 - auc: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9969 - val_precision: 0.9884 - val_recall: 0.9805 - val_auc: 0.9981\n",
      "Epoch 21/50\n",
      "1484/1484 [==============================] - 618s 417ms/step - loss: 0.0682 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9998 - auc: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9971 - val_precision: 0.9892 - val_recall: 0.9816 - val_auc: 0.9983\n",
      "Epoch 22/50\n",
      "1484/1484 [==============================] - 618s 417ms/step - loss: 0.0682 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9971 - val_precision: 0.9890 - val_recall: 0.9824 - val_auc: 0.9981\n",
      "Epoch 23/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1484/1484 [==============================] - 618s 417ms/step - loss: 0.0681 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9963 - val_precision: 0.9857 - val_recall: 0.9767 - val_auc: 0.9963\n",
      "Epoch 24/50\n",
      "1484/1484 [==============================] - 618s 416ms/step - loss: 0.0681 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9971 - val_precision: 0.9892 - val_recall: 0.9818 - val_auc: 0.9982\n",
      "Epoch 25/50\n",
      "1484/1484 [==============================] - 618s 416ms/step - loss: 0.0680 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9970 - val_precision: 0.9894 - val_recall: 0.9805 - val_auc: 0.9983\n",
      "Epoch 26/50\n",
      "1484/1484 [==============================] - 616s 415ms/step - loss: 0.0680 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9971 - val_precision: 0.9902 - val_recall: 0.9812 - val_auc: 0.9983\n",
      "Epoch 27/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484/1484 [==============================] - 613s 413ms/step - loss: 0.0680 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9968 - val_precision: 0.9880 - val_recall: 0.9803 - val_auc: 0.9981\n",
      "Epoch 28/50\n",
      "1484/1484 [==============================] - 616s 415ms/step - loss: 0.0680 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9971 - val_precision: 0.9898 - val_recall: 0.9810 - val_auc: 0.9981\n",
      "Epoch 29/50\n",
      "1484/1484 [==============================] - 615s 414ms/step - loss: 0.0680 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9971 - val_precision: 0.9898 - val_recall: 0.9807 - val_auc: 0.9982\n",
      "Epoch 30/50\n",
      "1484/1484 [==============================] - 615s 414ms/step - loss: 0.0679 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9971 - val_precision: 0.9900 - val_recall: 0.9806 - val_auc: 0.9982\n",
      "Epoch 31/50\n",
      "1483/1484 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "1484/1484 [==============================] - 621s 418ms/step - loss: 0.0679 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9969 - val_precision: 0.9890 - val_recall: 0.9801 - val_auc: 0.9980\n",
      "Epoch 32/50\n",
      " 349/1484 [======>.......................] - ETA: 7:35 - loss: 0.0679 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000"
     ]
    }
   ],
   "source": [
    "model1.fit(train_gen,\n",
    "          validation_data=val_gen,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          steps_per_epoch= int(len(files_train)//num_batch_size),\n",
    "          validation_steps=int(len(files_val)//num_batch_size),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae331f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
